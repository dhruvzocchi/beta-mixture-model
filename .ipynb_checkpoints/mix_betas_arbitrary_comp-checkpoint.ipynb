{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MLE functions\n",
    "def partition_list( lst , partition_length , num_partitions):\n",
    "    partitioned_list = []\n",
    "    for i in range(num_partitions):\n",
    "    #in case partition_length does not divide data equally, on the last\n",
    "    #iteration of the for loop, dump all remaining data into last partition\n",
    "        if i==num_partitions-1:\n",
    "            partitioned_list.append( lst[ partition_length * i : ] ) \n",
    "        else:\n",
    "            partitioned_list.append( lst[ partition_length * i : \n",
    "                                           partition_length * (i+1) ] )\n",
    "    return partitioned_list\n",
    "    \n",
    "def mix_betas( data , params , weights):\n",
    "    beta_list = []\n",
    "    #params is flat list of shape parameters- [a1,b1,a2,b2...]\n",
    "    #weights is flat list of distribution weights- [w1,w2...]\n",
    "    for i in range(0 , len(params) , 2):\n",
    "        beta_list.append( weights[ int( i/2 ) ] * stats.beta.pdf( data,\n",
    "                                                    params[ i ] , params[ i + 1 ] ,\n",
    "                                                    loc = 0 , scale = 1 ) )\n",
    "    \n",
    "    return np.sum( beta_list , axis = 0) \n",
    "    \n",
    "def neg_log_lik( params , weights , data):\n",
    "    return -np.sum( np.log( mix_betas( data , params , weights ) ) )\n",
    "\n",
    "def initial_param_guess(data , num_components):    \n",
    "    mean = np.mean(data)\n",
    "    var = np.var(data)\n",
    "    intermediate = mean * ( 1 - mean ) / var - 1\n",
    "    alpha = mean * intermediate\n",
    "    beta = ( 1 - mean ) * intermediate\n",
    "    return alpha , beta\n",
    "\n",
    "def update_mix(data , params , weights):\n",
    "    numer_list = []\n",
    "    for i in range(0 , len(params) , 2):\n",
    "        numer_list.append( weights[ int( i/2 ) ] * stats.beta.pdf(data, \n",
    "                                                    params[ i ] , params[ i + 1 ] ,\n",
    "                                                    loc = 0 , scale = 1 ) )\n",
    "    denom = np.sum( numer_list , axis = 0)    \n",
    " \n",
    "    w_list=[]\n",
    "    for numer in numer_list:\n",
    "        r = (numer/denom)\n",
    "        w_list.append( r.sum() / len(data) )\n",
    "    return np.array(w_list)\n",
    "\n",
    "def calc_beta_mean_var(a,b):\n",
    "    return a/(a+b) , (a*b) / ( (a+b)**2 * (a+b+1) )\n",
    "\n",
    "def predict_label(data , params , weights):\n",
    "    numer_list=[]\n",
    "    for i in range(0 , len(params) , 2):\n",
    "        numer_list.append( weights[ int( i/2 ) ] * stats.beta.pdf( data , \n",
    "                                                      params[i] , params[i+1] , \n",
    "                                                      loc = 0 , scale = 1 ) )\n",
    "    norm = np.sum( numer_list , axis = 0 )\n",
    "\n",
    "    \n",
    "    prob_list=[]\n",
    "    for numer in numer_list:\n",
    "        prob_list.append( numer / norm)\n",
    "    return prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "any 0 values - (array([], dtype=int64),)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## simulate/load data\n",
    "\n",
    "simulate = False\n",
    "data_dir = '/nrs/ahrens/DZ/22-Dec/2p_ablate_analysis/'\n",
    "data_file = 'main_data_post.txt'\n",
    "\n",
    "\n",
    "if simulate:\n",
    "    input_parameters = [1 , 5 , 4 , 2 , 10 , 10]\n",
    "    input_weights = [0.3 , 0.5 , 0.2]\n",
    "    num_samples = 1000\n",
    "\n",
    "    d1 = stats.beta.rvs( input_parameters[0] , input_parameters[1] ,\n",
    "                        loc = 0 , scale = 1 ,\n",
    "                        size = int(input_weights[0] * num_samples) , random_state = None )\n",
    "\n",
    "    d2 = stats.beta.rvs( input_parameters[2] , input_parameters[3] , \n",
    "                        loc = 0 , scale = 1 ,\n",
    "                        size = int(input_weights[1] * num_samples) , random_state = None )\n",
    "\n",
    "    d3 = stats.beta.rvs( input_parameters[4] , input_parameters[5]  , \n",
    "                        loc = 0 , scale = 1 , \n",
    "                        size = int(input_weights[2] * num_samples) , random_state = None )\n",
    "\n",
    "    data=np.concatenate( [ d1 , d2 , d3 ] )\n",
    "    plt.hist(data,density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n",
    "else:\n",
    "    data = np.loadtxt(data_dir + data_file)\n",
    "    data[np.where(data==0)]=0.001\n",
    "\n",
    "    for d in data:\n",
    "        plt.plot(d,0.1,'bx')\n",
    "\n",
    "    plt.hist(data,density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n",
    "\n",
    "    print('any 0 values - '+str(np.where(data==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -50.796257\n",
      "         Iterations: 215\n",
      "         Function evaluations: 368\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.796937\n",
      "         Iterations: 96\n",
      "         Function evaluations: 172\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.797760\n",
      "         Iterations: 83\n",
      "         Function evaluations: 155\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.798757\n",
      "         Iterations: 89\n",
      "         Function evaluations: 164\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.799962\n",
      "         Iterations: 98\n",
      "         Function evaluations: 175\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.801417\n",
      "         Iterations: 87\n",
      "         Function evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.803164\n",
      "         Iterations: 86\n",
      "         Function evaluations: 159\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.805245\n",
      "         Iterations: 89\n",
      "         Function evaluations: 161\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.807694\n",
      "         Iterations: 90\n",
      "         Function evaluations: 166\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.810529\n",
      "         Iterations: 94\n",
      "         Function evaluations: 164\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.813746\n",
      "         Iterations: 103\n",
      "         Function evaluations: 182\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.817309\n",
      "         Iterations: 105\n",
      "         Function evaluations: 190\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.821153\n",
      "         Iterations: 112\n",
      "         Function evaluations: 201\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.825186\n",
      "         Iterations: 108\n",
      "         Function evaluations: 189\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.829302\n",
      "         Iterations: 100\n",
      "         Function evaluations: 183\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.833393\n",
      "         Iterations: 107\n",
      "         Function evaluations: 193\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.837360\n",
      "         Iterations: 108\n",
      "         Function evaluations: 192\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.841125\n",
      "         Iterations: 110\n",
      "         Function evaluations: 194\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.844629\n",
      "         Iterations: 98\n",
      "         Function evaluations: 172\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.847837\n",
      "         Iterations: 95\n",
      "         Function evaluations: 172\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.850733\n",
      "         Iterations: 109\n",
      "         Function evaluations: 194\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.853316\n",
      "         Iterations: 120\n",
      "         Function evaluations: 212\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.855597\n",
      "         Iterations: 98\n",
      "         Function evaluations: 180\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.857596\n",
      "         Iterations: 91\n",
      "         Function evaluations: 165\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.859334\n",
      "         Iterations: 100\n",
      "         Function evaluations: 179\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.860839\n",
      "         Iterations: 101\n",
      "         Function evaluations: 187\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.862134\n",
      "         Iterations: 102\n",
      "         Function evaluations: 180\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.863246\n",
      "         Iterations: 115\n",
      "         Function evaluations: 202\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.864197\n",
      "         Iterations: 101\n",
      "         Function evaluations: 182\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.865009\n",
      "         Iterations: 102\n",
      "         Function evaluations: 182\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.865701\n",
      "         Iterations: 103\n",
      "         Function evaluations: 183\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.866289\n",
      "         Iterations: 87\n",
      "         Function evaluations: 159\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.866788\n",
      "         Iterations: 105\n",
      "         Function evaluations: 189\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.867213\n",
      "         Iterations: 83\n",
      "         Function evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.867572\n",
      "         Iterations: 102\n",
      "         Function evaluations: 182\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.867877\n",
      "         Iterations: 76\n",
      "         Function evaluations: 141\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.868135\n",
      "         Iterations: 92\n",
      "         Function evaluations: 168\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.868354\n",
      "         Iterations: 81\n",
      "         Function evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.868540\n",
      "         Iterations: 90\n",
      "         Function evaluations: 166\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.868697\n",
      "         Iterations: 77\n",
      "         Function evaluations: 142\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.868830\n",
      "         Iterations: 89\n",
      "         Function evaluations: 161\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.868942\n",
      "         Iterations: 93\n",
      "         Function evaluations: 172\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869038\n",
      "         Iterations: 92\n",
      "         Function evaluations: 168\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869118\n",
      "         Iterations: 79\n",
      "         Function evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869187\n",
      "         Iterations: 72\n",
      "         Function evaluations: 139\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869245\n",
      "         Iterations: 74\n",
      "         Function evaluations: 137\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869294\n",
      "         Iterations: 79\n",
      "         Function evaluations: 146\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869335\n",
      "         Iterations: 90\n",
      "         Function evaluations: 162\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869371\n",
      "         Iterations: 79\n",
      "         Function evaluations: 147\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869401\n",
      "         Iterations: 84\n",
      "         Function evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869426\n",
      "         Iterations: 81\n",
      "         Function evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869447\n",
      "         Iterations: 85\n",
      "         Function evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869466\n",
      "         Iterations: 79\n",
      "         Function evaluations: 145\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869481\n",
      "         Iterations: 85\n",
      "         Function evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869494\n",
      "         Iterations: 86\n",
      "         Function evaluations: 155\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869505\n",
      "         Iterations: 84\n",
      "         Function evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869515\n",
      "         Iterations: 79\n",
      "         Function evaluations: 148\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869523\n",
      "         Iterations: 86\n",
      "         Function evaluations: 154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869530\n",
      "         Iterations: 86\n",
      "         Function evaluations: 159\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869535\n",
      "         Iterations: 83\n",
      "         Function evaluations: 153\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869540\n",
      "         Iterations: 83\n",
      "         Function evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869544\n",
      "         Iterations: 92\n",
      "         Function evaluations: 162\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869548\n",
      "         Iterations: 96\n",
      "         Function evaluations: 173\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869551\n",
      "         Iterations: 85\n",
      "         Function evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869554\n",
      "         Iterations: 67\n",
      "         Function evaluations: 128\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869556\n",
      "         Iterations: 91\n",
      "         Function evaluations: 161\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869558\n",
      "         Iterations: 80\n",
      "         Function evaluations: 146\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869559\n",
      "         Iterations: 82\n",
      "         Function evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869560\n",
      "         Iterations: 88\n",
      "         Function evaluations: 160\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869562\n",
      "         Iterations: 85\n",
      "         Function evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869562\n",
      "         Iterations: 83\n",
      "         Function evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869563\n",
      "         Iterations: 87\n",
      "         Function evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869564\n",
      "         Iterations: 83\n",
      "         Function evaluations: 150\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869565\n",
      "         Iterations: 84\n",
      "         Function evaluations: 149\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869565\n",
      "         Iterations: 81\n",
      "         Function evaluations: 146\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869565\n",
      "         Iterations: 87\n",
      "         Function evaluations: 155\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869566\n",
      "         Iterations: 91\n",
      "         Function evaluations: 161\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869566\n",
      "         Iterations: 86\n",
      "         Function evaluations: 151\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869566\n",
      "         Iterations: 96\n",
      "         Function evaluations: 169\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869567\n",
      "         Iterations: 102\n",
      "         Function evaluations: 178\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869567\n",
      "         Iterations: 91\n",
      "         Function evaluations: 157\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869567\n",
      "         Iterations: 92\n",
      "         Function evaluations: 162\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869567\n",
      "         Iterations: 93\n",
      "         Function evaluations: 159\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869567\n",
      "         Iterations: 89\n",
      "         Function evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869567\n",
      "         Iterations: 83\n",
      "         Function evaluations: 148\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869567\n",
      "         Iterations: 89\n",
      "         Function evaluations: 154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869567\n",
      "         Iterations: 90\n",
      "         Function evaluations: 157\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869567\n",
      "         Iterations: 88\n",
      "         Function evaluations: 154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 92\n",
      "         Function evaluations: 161\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 90\n",
      "         Function evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 91\n",
      "         Function evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 90\n",
      "         Function evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 95\n",
      "         Function evaluations: 164\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 95\n",
      "         Function evaluations: 165\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 90\n",
      "         Function evaluations: 154\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 92\n",
      "         Function evaluations: 159\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 93\n",
      "         Function evaluations: 160\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 99\n",
      "         Function evaluations: 167\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 99\n",
      "         Function evaluations: 167\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 99\n",
      "         Function evaluations: 167\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 91\n",
      "         Function evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 91\n",
      "         Function evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 96\n",
      "         Function evaluations: 164\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 101\n",
      "         Function evaluations: 168\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 91\n",
      "         Function evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 100\n",
      "         Function evaluations: 169\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 90\n",
      "         Function evaluations: 157\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 95\n",
      "         Function evaluations: 163\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 92\n",
      "         Function evaluations: 158\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 91\n",
      "         Function evaluations: 156\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 94\n",
      "         Function evaluations: 162\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 98\n",
      "         Function evaluations: 168\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 91\n",
      "         Function evaluations: 157\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 94\n",
      "         Function evaluations: 160\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 99\n",
      "         Function evaluations: 168\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 99\n",
      "         Function evaluations: 165\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 97\n",
      "         Function evaluations: 162\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 100\n",
      "         Function evaluations: 167\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 96\n",
      "         Function evaluations: 161\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 95\n",
      "         Function evaluations: 160\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 101\n",
      "         Function evaluations: 170\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 100\n",
      "         Function evaluations: 168\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 95\n",
      "         Function evaluations: 160\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 98\n",
      "         Function evaluations: 165\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 100\n",
      "         Function evaluations: 169\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 100\n",
      "         Function evaluations: 166\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 102\n",
      "         Function evaluations: 169\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 102\n",
      "         Function evaluations: 168\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -50.869568\n",
      "         Iterations: 98\n",
      "         Function evaluations: 164\n"
     ]
    }
   ],
   "source": [
    "### fit beta mixture model to data\n",
    "\n",
    "num_components = 2\n",
    "tolerance = 1e-10\n",
    "\n",
    "# sort data, lowest to highest, then partition data into the number \n",
    "# of components specified above to feed seperately to generate initial params\n",
    "sorted_data = np.sort(data)\n",
    "partition_length = int( len( sorted_data ) / num_components)\n",
    "\n",
    "partitioned_data = partition_list( sorted_data , partition_length , num_components)\n",
    "\n",
    "## calculate initial guesses for shape parameters using method of moments\n",
    "## on each partitioned data set, and set initial weights to equiprobable \n",
    "## for each distribution\n",
    "init_params = []\n",
    "for part in partitioned_data:\n",
    "    a , b = initial_param_guess( part , num_components)\n",
    "    init_params.append( a )\n",
    "    init_params.append( b )\n",
    "init_weights = [1/num_components] * num_components\n",
    "#init_params is a list containing shape params- [alpha1, beta1, alpha2, beta2...]\n",
    "#init_weights is a list with the corresponding weights- [w1,w2...]\n",
    "\n",
    "\n",
    "## run first maximization step, store neg log-likelihood value\n",
    "\n",
    "# hold weights constants, and find shape params that minimize\n",
    "# the neg log-likelihood function. Args in scipy 'minimize' are \n",
    "# passed to the function being minimized and are held\n",
    "# constant during the minimization\n",
    "mle_fit=minimize(neg_log_lik , \n",
    "                 init_params , args = (init_weights , data ,) ,\n",
    "                 method = 'NELDER-MEAD', options={'disp': True} )\n",
    "\n",
    "# run the EM algorithm until change in neg log-likelihood is\n",
    "# within the tolerance set above\n",
    "weights = init_weights\n",
    "neg_ll_hist = [ 0 , mle_fit.fun ]\n",
    "param_hist = [ mle_fit.x ]\n",
    "while abs(neg_ll_hist[-1] - neg_ll_hist[-2]) > tolerance:\n",
    "\n",
    "    #update mixture values using new values of shape params\n",
    "    params = mle_fit.x\n",
    "    weights = update_mix(data , params , weights)\n",
    "\n",
    "    #run next maximization to get new shape params\n",
    "    mle_fit=minimize(neg_log_lik , \n",
    "                 params , args = (weights , data ,) ,\n",
    "                 method = 'NELDER-MEAD', options={'disp': True} )\n",
    "\n",
    "    #update history lists\n",
    "    param_hist.append(mle_fit.x)\n",
    "    neg_ll_hist.append(mle_fit.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit params- [ 0.86426421  5.9782638   7.64873158 34.20336194]\n",
      "fit weights- [0.61937607 0.38062393]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot weighted distributions over data histogram\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.hist(data,density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n",
    "x = np.linspace(0,1,1000)\n",
    "color_list = ['b' , 'r' , 'g']\n",
    "for i in range(0 , len(params) , 2):\n",
    "    ax.plot(x, \n",
    "            weights[ int( i/2 ) ] * stats.beta.pdf( x, params[ i ] , params[ i + 1 ]),\n",
    "            color_list[int(i/2)] , lw=5, alpha=0.6, label='beta pdf')\n",
    "    plt.fill_between(x , \n",
    "            weights[ int( i/2 ) ] * stats.beta.pdf( x, params[ i ] , params[ i + 1 ] ) ,\n",
    "                    color = color_list[int(i/2)])\n",
    "\n",
    "ax.set_ylim( 0 , 12 )\n",
    "ax.set_xlim( 0 , 1 )\n",
    "\n",
    "if simulate:\n",
    "    print('input params- ' + str(input_parameters))\n",
    "    print('fit params- ' + str(params))\n",
    "    print('input weights- ' + str(input_weights))\n",
    "    print('fit weights- ' + str(weights))\n",
    "else:\n",
    "    print('fit params- ' + str(params))\n",
    "    print('fit weights- ' + str(weights))\n",
    "#plt.savefig(data_dir+'post_weighted.eps',format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare log-likelihoods of fit vs original distribution\n",
    "\n",
    "print('log likelihood fit = ' + str(-neg_log_lik( params , weights , data ) ) )\n",
    "print('log likelihood original dist = ' + str(-neg_log_lik( input_parameters , input_weights , data ) ) )\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "x = np.linspace(0,1,1000)\n",
    "ax.hist(data,density=True, bins='auto', histtype='stepfilled', alpha=0.2)\n",
    "ax.plot(x, mix_betas( x , params , weights ),\n",
    "       'r-', lw=5, alpha=0.6, label='beta pdf')\n",
    "\n",
    "ax.plot(x, mix_betas( x , input_parameters , input_weights ),\n",
    "       'b-', lw=5, alpha=0.6, label='beta pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0412666666666667, 0.0870333333333333, 0.0333725490196078, 0.0235, 0.435783333333333, 0.10925, 0.116766666666667, 0.109, 0.0623, 0.102, 0.0291, 0.0487, 0.1146, 0.099, 0.055, 0.084, 0.0303, 0.001, 0.0646, 0.383, 0.01, 0.11, 0.001, 0.4, 0.08, 0.02] [0.1277, 0.25315, 0.19245, 0.18403509, 0.2124, 0.2019, 0.1277, 0.1339, 0.182, 0.249, 0.247, 0.217, 0.22, 0.254, 0.2097, 0.2392, 0.1583, 0.1683, 0.1436, 0.2207, 0.2301, 0.22, 0.1332, 0.2475]\n"
     ]
    }
   ],
   "source": [
    "## assign data points to the component distributions\n",
    "p_list = predict_label( data, params , weights )\n",
    "\n",
    "\n",
    "#create a list of lists for the different groupings\n",
    "header_count = num_components + 1\n",
    "\n",
    "headers = [[] for i in range(1, header_count)]\n",
    "prob = np.zeros( [ num_components , data.shape[0] ] )\n",
    "for i , p in enumerate(p_list):\n",
    "    prob[ i , : ] = p\n",
    "    \n",
    "for i in range(data.shape[0]):\n",
    "\n",
    "    ret = np.argmax( prob[: , i] )\n",
    "    #print(ret)\n",
    "    headers[ ret ].append(data[ i ])\n",
    "print(headers[0] , headers[1])\n",
    "#for i in range(num_components):\n",
    "    \n",
    "#    np.savetxt(data_dir + 'data_component' + str(i) + '.txt' , headers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
